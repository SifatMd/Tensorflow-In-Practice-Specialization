{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOwsuGQQY9OL",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8d633a1d-9005-48ec-cedf-3537fd2b791c"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSzo9o2WJ_dJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54051d20-11dd-40aa-87bd-f99134434a07"
      },
      "source": [
        "print(corpus[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in the town of athy one jeremy lanigan \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvrOCcOHJpsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220a9006-5d7a-47c5-acf5-ee85dbd40f88"
      },
      "source": [
        "token_list = tokenizer.texts_to_sequences([corpus[0]])\n",
        "print(token_list)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4, 2, 66, 8, 67, 68, 69, 70]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "soPGVheskaQP",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "#create one hot \n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pJtwVB2NbOAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d255f47b-5f91-4ec4-f579-655f8b3d07ef"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49Cv68JOakwv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b73814f-ea8e-4caa-ca6b-98cbd88ed5a8"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY-jwvfgbEF8",
        "colab": {}
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wtzlUMYadhKt",
        "colab": {}
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H4myRpB1c4Gg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "74915d32-332e-47dd-838f-a7a9b2f974ae"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3553ae7-7317-426a-d5ce-2c1ecd7f3cf4"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=350, verbose=1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5689 - accuracy: 0.0110\n",
            "Epoch 2/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.5466 - accuracy: 0.0574\n",
            "Epoch 3/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.4995 - accuracy: 0.0640\n",
            "Epoch 4/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.3473 - accuracy: 0.0552\n",
            "Epoch 5/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.1460 - accuracy: 0.0508\n",
            "Epoch 6/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0744 - accuracy: 0.0508\n",
            "Epoch 7/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0409 - accuracy: 0.0419\n",
            "Epoch 8/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0122 - accuracy: 0.0530\n",
            "Epoch 9/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9894 - accuracy: 0.0508\n",
            "Epoch 10/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9629 - accuracy: 0.0530\n",
            "Epoch 11/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9346 - accuracy: 0.0574\n",
            "Epoch 12/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9023 - accuracy: 0.0552\n",
            "Epoch 13/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8667 - accuracy: 0.0552\n",
            "Epoch 14/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.8300 - accuracy: 0.0552\n",
            "Epoch 15/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.7830 - accuracy: 0.0596\n",
            "Epoch 16/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.7467 - accuracy: 0.0684\n",
            "Epoch 17/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6984 - accuracy: 0.0662\n",
            "Epoch 18/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6523 - accuracy: 0.0530\n",
            "Epoch 19/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6052 - accuracy: 0.0486\n",
            "Epoch 20/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.5646 - accuracy: 0.0706\n",
            "Epoch 21/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.5241 - accuracy: 0.0751\n",
            "Epoch 22/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4902 - accuracy: 0.0795\n",
            "Epoch 23/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4500 - accuracy: 0.0949\n",
            "Epoch 24/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4083 - accuracy: 0.1038\n",
            "Epoch 25/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.3723 - accuracy: 0.1038\n",
            "Epoch 26/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.3353 - accuracy: 0.0993\n",
            "Epoch 27/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2953 - accuracy: 0.1060\n",
            "Epoch 28/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2572 - accuracy: 0.1148\n",
            "Epoch 29/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2206 - accuracy: 0.1325\n",
            "Epoch 30/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.1791 - accuracy: 0.1413\n",
            "Epoch 31/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.1452 - accuracy: 0.1369\n",
            "Epoch 32/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.1086 - accuracy: 0.1435\n",
            "Epoch 33/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0578 - accuracy: 0.1457\n",
            "Epoch 34/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0136 - accuracy: 0.1501\n",
            "Epoch 35/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.9714 - accuracy: 0.1678\n",
            "Epoch 36/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.9359 - accuracy: 0.1744\n",
            "Epoch 37/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8871 - accuracy: 0.2009\n",
            "Epoch 38/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8540 - accuracy: 0.2031\n",
            "Epoch 39/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8122 - accuracy: 0.2119\n",
            "Epoch 40/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7689 - accuracy: 0.2009\n",
            "Epoch 41/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7150 - accuracy: 0.2119\n",
            "Epoch 42/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6690 - accuracy: 0.2053\n",
            "Epoch 43/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6226 - accuracy: 0.2318\n",
            "Epoch 44/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.5750 - accuracy: 0.2428\n",
            "Epoch 45/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.5413 - accuracy: 0.2561\n",
            "Epoch 46/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.5068 - accuracy: 0.2517\n",
            "Epoch 47/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.4609 - accuracy: 0.2539\n",
            "Epoch 48/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.4235 - accuracy: 0.2627\n",
            "Epoch 49/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.3751 - accuracy: 0.2848\n",
            "Epoch 50/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.3386 - accuracy: 0.2848\n",
            "Epoch 51/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.2952 - accuracy: 0.3024\n",
            "Epoch 52/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.2476 - accuracy: 0.3179\n",
            "Epoch 53/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.2053 - accuracy: 0.3245\n",
            "Epoch 54/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1643 - accuracy: 0.3532\n",
            "Epoch 55/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1326 - accuracy: 0.3664\n",
            "Epoch 56/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1211 - accuracy: 0.3532\n",
            "Epoch 57/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.0822 - accuracy: 0.3664\n",
            "Epoch 58/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.0350 - accuracy: 0.3797\n",
            "Epoch 59/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.0031 - accuracy: 0.3929\n",
            "Epoch 60/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9545 - accuracy: 0.4040\n",
            "Epoch 61/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9215 - accuracy: 0.4150\n",
            "Epoch 62/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8791 - accuracy: 0.4283\n",
            "Epoch 63/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8490 - accuracy: 0.4216\n",
            "Epoch 64/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8100 - accuracy: 0.4592\n",
            "Epoch 65/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7824 - accuracy: 0.4614\n",
            "Epoch 66/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7521 - accuracy: 0.4724\n",
            "Epoch 67/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7170 - accuracy: 0.4834\n",
            "Epoch 68/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6819 - accuracy: 0.4857\n",
            "Epoch 69/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6554 - accuracy: 0.5099\n",
            "Epoch 70/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6408 - accuracy: 0.4945\n",
            "Epoch 71/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.6018 - accuracy: 0.5099\n",
            "Epoch 72/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5636 - accuracy: 0.5364\n",
            "Epoch 73/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5301 - accuracy: 0.5430\n",
            "Epoch 74/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5019 - accuracy: 0.5386\n",
            "Epoch 75/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4796 - accuracy: 0.5607\n",
            "Epoch 76/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4470 - accuracy: 0.5453\n",
            "Epoch 77/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.4124 - accuracy: 0.5762\n",
            "Epoch 78/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3839 - accuracy: 0.5850\n",
            "Epoch 79/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3554 - accuracy: 0.5872\n",
            "Epoch 80/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3196 - accuracy: 0.5850\n",
            "Epoch 81/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3111 - accuracy: 0.6049\n",
            "Epoch 82/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2809 - accuracy: 0.6026\n",
            "Epoch 83/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2554 - accuracy: 0.5916\n",
            "Epoch 84/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2282 - accuracy: 0.6071\n",
            "Epoch 85/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2000 - accuracy: 0.6115\n",
            "Epoch 86/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1714 - accuracy: 0.6181\n",
            "Epoch 87/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1506 - accuracy: 0.6225\n",
            "Epoch 88/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1268 - accuracy: 0.6380\n",
            "Epoch 89/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0978 - accuracy: 0.6336\n",
            "Epoch 90/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1017 - accuracy: 0.6291\n",
            "Epoch 91/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.0727 - accuracy: 0.6446\n",
            "Epoch 92/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0460 - accuracy: 0.6468\n",
            "Epoch 93/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0232 - accuracy: 0.6468\n",
            "Epoch 94/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9925 - accuracy: 0.6711\n",
            "Epoch 95/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9655 - accuracy: 0.6490\n",
            "Epoch 96/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9350 - accuracy: 0.6711\n",
            "Epoch 97/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9157 - accuracy: 0.6711\n",
            "Epoch 98/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8853 - accuracy: 0.6799\n",
            "Epoch 99/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8600 - accuracy: 0.6777\n",
            "Epoch 100/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8449 - accuracy: 0.6865\n",
            "Epoch 101/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8279 - accuracy: 0.6865\n",
            "Epoch 102/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7972 - accuracy: 0.6976\n",
            "Epoch 103/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7738 - accuracy: 0.7130\n",
            "Epoch 104/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7547 - accuracy: 0.7307\n",
            "Epoch 105/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7389 - accuracy: 0.7439\n",
            "Epoch 106/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7111 - accuracy: 0.7417\n",
            "Epoch 107/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6896 - accuracy: 0.7550\n",
            "Epoch 108/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6674 - accuracy: 0.7528\n",
            "Epoch 109/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6529 - accuracy: 0.7483\n",
            "Epoch 110/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6251 - accuracy: 0.7439\n",
            "Epoch 111/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6081 - accuracy: 0.7528\n",
            "Epoch 112/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5903 - accuracy: 0.7528\n",
            "Epoch 113/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5966 - accuracy: 0.7461\n",
            "Epoch 114/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5810 - accuracy: 0.7594\n",
            "Epoch 115/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5808 - accuracy: 0.7461\n",
            "Epoch 116/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5684 - accuracy: 0.7461\n",
            "Epoch 117/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5301 - accuracy: 0.7572\n",
            "Epoch 118/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5053 - accuracy: 0.7616\n",
            "Epoch 119/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4771 - accuracy: 0.7726\n",
            "Epoch 120/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4575 - accuracy: 0.7726\n",
            "Epoch 121/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4313 - accuracy: 0.7704\n",
            "Epoch 122/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4289 - accuracy: 0.7792\n",
            "Epoch 123/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4113 - accuracy: 0.7704\n",
            "Epoch 124/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3857 - accuracy: 0.7815\n",
            "Epoch 125/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3678 - accuracy: 0.7792\n",
            "Epoch 126/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3450 - accuracy: 0.7969\n",
            "Epoch 127/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3283 - accuracy: 0.8057\n",
            "Epoch 128/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3091 - accuracy: 0.8057\n",
            "Epoch 129/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2932 - accuracy: 0.8168\n",
            "Epoch 130/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2764 - accuracy: 0.8212\n",
            "Epoch 131/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2630 - accuracy: 0.8300\n",
            "Epoch 132/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2676 - accuracy: 0.8168\n",
            "Epoch 133/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2532 - accuracy: 0.8344\n",
            "Epoch 134/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2343 - accuracy: 0.8389\n",
            "Epoch 135/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2407 - accuracy: 0.8278\n",
            "Epoch 136/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2280 - accuracy: 0.8124\n",
            "Epoch 137/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1973 - accuracy: 0.8433\n",
            "Epoch 138/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1801 - accuracy: 0.8477\n",
            "Epoch 139/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1651 - accuracy: 0.8389\n",
            "Epoch 140/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1407 - accuracy: 0.8477\n",
            "Epoch 141/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1268 - accuracy: 0.8499\n",
            "Epoch 142/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1111 - accuracy: 0.8609\n",
            "Epoch 143/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0956 - accuracy: 0.8609\n",
            "Epoch 144/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0781 - accuracy: 0.8609\n",
            "Epoch 145/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0628 - accuracy: 0.8609\n",
            "Epoch 146/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0540 - accuracy: 0.8675\n",
            "Epoch 147/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0365 - accuracy: 0.8742\n",
            "Epoch 148/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0302 - accuracy: 0.8764\n",
            "Epoch 149/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0157 - accuracy: 0.8786\n",
            "Epoch 150/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0022 - accuracy: 0.8830\n",
            "Epoch 151/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9876 - accuracy: 0.8896\n",
            "Epoch 152/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9753 - accuracy: 0.8940\n",
            "Epoch 153/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9613 - accuracy: 0.8918\n",
            "Epoch 154/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9493 - accuracy: 0.8896\n",
            "Epoch 155/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9373 - accuracy: 0.8918\n",
            "Epoch 156/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9279 - accuracy: 0.8985\n",
            "Epoch 157/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9155 - accuracy: 0.9051\n",
            "Epoch 158/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9049 - accuracy: 0.9073\n",
            "Epoch 159/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8944 - accuracy: 0.9029\n",
            "Epoch 160/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8843 - accuracy: 0.9073\n",
            "Epoch 161/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8734 - accuracy: 0.9073\n",
            "Epoch 162/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8635 - accuracy: 0.9095\n",
            "Epoch 163/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8526 - accuracy: 0.9051\n",
            "Epoch 164/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8454 - accuracy: 0.9051\n",
            "Epoch 165/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8330 - accuracy: 0.9029\n",
            "Epoch 166/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8234 - accuracy: 0.9095\n",
            "Epoch 167/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8134 - accuracy: 0.9051\n",
            "Epoch 168/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8062 - accuracy: 0.9117\n",
            "Epoch 169/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7974 - accuracy: 0.9051\n",
            "Epoch 170/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7863 - accuracy: 0.9095\n",
            "Epoch 171/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7783 - accuracy: 0.9161\n",
            "Epoch 172/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7677 - accuracy: 0.9183\n",
            "Epoch 173/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7600 - accuracy: 0.9183\n",
            "Epoch 174/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7504 - accuracy: 0.9139\n",
            "Epoch 175/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.9183\n",
            "Epoch 176/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7341 - accuracy: 0.9227\n",
            "Epoch 177/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7257 - accuracy: 0.9272\n",
            "Epoch 178/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7182 - accuracy: 0.9249\n",
            "Epoch 179/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7116 - accuracy: 0.9227\n",
            "Epoch 180/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.9205\n",
            "Epoch 181/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.9272\n",
            "Epoch 182/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.9272\n",
            "Epoch 183/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.9161\n",
            "Epoch 184/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.9294\n",
            "Epoch 185/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.9272\n",
            "Epoch 186/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.9161\n",
            "Epoch 187/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7450 - accuracy: 0.9007\n",
            "Epoch 188/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7530 - accuracy: 0.9029\n",
            "Epoch 189/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7341 - accuracy: 0.8962\n",
            "Epoch 190/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7181 - accuracy: 0.9007\n",
            "Epoch 191/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7370 - accuracy: 0.9029\n",
            "Epoch 192/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7338 - accuracy: 0.8940\n",
            "Epoch 193/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7469 - accuracy: 0.8985\n",
            "Epoch 194/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7289 - accuracy: 0.9029\n",
            "Epoch 195/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.9139\n",
            "Epoch 196/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.9051\n",
            "Epoch 197/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.9117\n",
            "Epoch 198/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.9183\n",
            "Epoch 199/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.9272\n",
            "Epoch 200/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.9316\n",
            "Epoch 201/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5816 - accuracy: 0.9382\n",
            "Epoch 202/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.9360\n",
            "Epoch 203/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.9382\n",
            "Epoch 204/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5661 - accuracy: 0.9426\n",
            "Epoch 205/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.9426\n",
            "Epoch 206/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.9448\n",
            "Epoch 207/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5452 - accuracy: 0.9426\n",
            "Epoch 208/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.9448\n",
            "Epoch 209/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.9448\n",
            "Epoch 210/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.9448\n",
            "Epoch 211/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.9448\n",
            "Epoch 212/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.9426\n",
            "Epoch 213/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.9426\n",
            "Epoch 214/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.9470\n",
            "Epoch 215/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.9470\n",
            "Epoch 216/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.9470\n",
            "Epoch 217/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.9448\n",
            "Epoch 218/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.9470\n",
            "Epoch 219/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.9470\n",
            "Epoch 220/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.9426\n",
            "Epoch 221/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.9448\n",
            "Epoch 222/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.9448\n",
            "Epoch 223/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.9470\n",
            "Epoch 224/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.9470\n",
            "Epoch 225/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.9470\n",
            "Epoch 226/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.9470\n",
            "Epoch 227/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.9470\n",
            "Epoch 228/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.9492\n",
            "Epoch 229/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.9492\n",
            "Epoch 230/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9492\n",
            "Epoch 231/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9470\n",
            "Epoch 232/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.9470\n",
            "Epoch 233/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.9492\n",
            "Epoch 234/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.9492\n",
            "Epoch 235/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.9492\n",
            "Epoch 236/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.9514\n",
            "Epoch 237/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.9514\n",
            "Epoch 238/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.9514\n",
            "Epoch 239/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.9492\n",
            "Epoch 240/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.9514\n",
            "Epoch 241/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.9470\n",
            "Epoch 242/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.9492\n",
            "Epoch 243/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.9492\n",
            "Epoch 244/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.9492\n",
            "Epoch 245/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.9470\n",
            "Epoch 246/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.9492\n",
            "Epoch 247/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.9448\n",
            "Epoch 248/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.9492\n",
            "Epoch 249/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.9514\n",
            "Epoch 250/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.9514\n",
            "Epoch 251/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.9492\n",
            "Epoch 252/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.9470\n",
            "Epoch 253/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.9470\n",
            "Epoch 254/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.9470\n",
            "Epoch 255/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.9448\n",
            "Epoch 256/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3452 - accuracy: 0.9470\n",
            "Epoch 257/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3432 - accuracy: 0.9492\n",
            "Epoch 258/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.9514\n",
            "Epoch 259/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3374 - accuracy: 0.9470\n",
            "Epoch 260/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.9514\n",
            "Epoch 261/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.9492\n",
            "Epoch 262/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.9470\n",
            "Epoch 263/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.9448\n",
            "Epoch 264/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3429 - accuracy: 0.9382\n",
            "Epoch 265/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.9382\n",
            "Epoch 266/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.9360\n",
            "Epoch 267/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.9360\n",
            "Epoch 268/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.9448\n",
            "Epoch 269/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.9404\n",
            "Epoch 270/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.9448\n",
            "Epoch 271/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.9338\n",
            "Epoch 272/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.9448\n",
            "Epoch 273/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.9448\n",
            "Epoch 274/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3364 - accuracy: 0.9470\n",
            "Epoch 275/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3247 - accuracy: 0.9470\n",
            "Epoch 276/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3210 - accuracy: 0.9492\n",
            "Epoch 277/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.9448\n",
            "Epoch 278/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3119 - accuracy: 0.9448\n",
            "Epoch 279/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.9470\n",
            "Epoch 280/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.9382\n",
            "Epoch 281/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3457 - accuracy: 0.9360\n",
            "Epoch 282/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.9360\n",
            "Epoch 283/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.9404\n",
            "Epoch 284/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3139 - accuracy: 0.9404\n",
            "Epoch 285/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3081 - accuracy: 0.9448\n",
            "Epoch 286/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3037 - accuracy: 0.9426\n",
            "Epoch 287/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3011 - accuracy: 0.9426\n",
            "Epoch 288/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2972 - accuracy: 0.9404\n",
            "Epoch 289/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2942 - accuracy: 0.9448\n",
            "Epoch 290/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2915 - accuracy: 0.9426\n",
            "Epoch 291/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2887 - accuracy: 0.9448\n",
            "Epoch 292/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.9448\n",
            "Epoch 293/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2841 - accuracy: 0.9382\n",
            "Epoch 294/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2832 - accuracy: 0.9404\n",
            "Epoch 295/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2799 - accuracy: 0.9404\n",
            "Epoch 296/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2766 - accuracy: 0.9448\n",
            "Epoch 297/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2752 - accuracy: 0.9426\n",
            "Epoch 298/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.9426\n",
            "Epoch 299/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2713 - accuracy: 0.9492\n",
            "Epoch 300/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2698 - accuracy: 0.9426\n",
            "Epoch 301/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.9448\n",
            "Epoch 302/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2647 - accuracy: 0.9426\n",
            "Epoch 303/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2636 - accuracy: 0.9448\n",
            "Epoch 304/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2605 - accuracy: 0.9404\n",
            "Epoch 305/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2592 - accuracy: 0.9470\n",
            "Epoch 306/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2590 - accuracy: 0.9360\n",
            "Epoch 307/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.9448\n",
            "Epoch 308/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2540 - accuracy: 0.9492\n",
            "Epoch 309/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2517 - accuracy: 0.9470\n",
            "Epoch 310/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.9426\n",
            "Epoch 311/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.9448\n",
            "Epoch 312/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9426\n",
            "Epoch 313/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2450 - accuracy: 0.9492\n",
            "Epoch 314/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2442 - accuracy: 0.9448\n",
            "Epoch 315/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2419 - accuracy: 0.9448\n",
            "Epoch 316/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2398 - accuracy: 0.9426\n",
            "Epoch 317/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2393 - accuracy: 0.9448\n",
            "Epoch 318/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9448\n",
            "Epoch 319/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2352 - accuracy: 0.9470\n",
            "Epoch 320/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2332 - accuracy: 0.9514\n",
            "Epoch 321/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2315 - accuracy: 0.9492\n",
            "Epoch 322/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2303 - accuracy: 0.9492\n",
            "Epoch 323/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2308 - accuracy: 0.9448\n",
            "Epoch 324/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.9492\n",
            "Epoch 325/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2275 - accuracy: 0.9470\n",
            "Epoch 326/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2258 - accuracy: 0.9514\n",
            "Epoch 327/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.9514\n",
            "Epoch 328/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2226 - accuracy: 0.9492\n",
            "Epoch 329/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2218 - accuracy: 0.9492\n",
            "Epoch 330/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.9448\n",
            "Epoch 331/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2189 - accuracy: 0.9514\n",
            "Epoch 332/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2172 - accuracy: 0.9492\n",
            "Epoch 333/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2165 - accuracy: 0.9492\n",
            "Epoch 334/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2149 - accuracy: 0.9492\n",
            "Epoch 335/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.9492\n",
            "Epoch 336/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2114 - accuracy: 0.9514\n",
            "Epoch 337/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2104 - accuracy: 0.9492\n",
            "Epoch 338/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2088 - accuracy: 0.9492\n",
            "Epoch 339/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9514\n",
            "Epoch 340/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9536\n",
            "Epoch 341/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2057 - accuracy: 0.9536\n",
            "Epoch 342/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2040 - accuracy: 0.9514\n",
            "Epoch 343/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2029 - accuracy: 0.9514\n",
            "Epoch 344/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9514\n",
            "Epoch 345/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9492\n",
            "Epoch 346/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1994 - accuracy: 0.9492\n",
            "Epoch 347/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9492\n",
            "Epoch 348/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1992 - accuracy: 0.9492\n",
            "Epoch 349/350\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1982 - accuracy: 0.9492\n",
            "Epoch 350/350\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1972 - accuracy: 0.9492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3YXGelKThoTT",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "poeprYK8h-c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "893e795b-b3be-4b11-e536-e084f3134384"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "769a1bc0-d115-4a34-a946-287852ce5617"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 10\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\tpredicted_temp = model.predict_class(token_list)\n",
        "\tprint('predicted token', predicted_temp)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5f856f4a0169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpredicted_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_class'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHEGtE9qRw6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}